# FFTNet for intelligibility-tensorflow-implementation
This repositary provides a tensorflow implementation of the FFTNet intelligibility enhancement model presented in <a href="https://ieeexplore.ieee.org/document/9611022">here</a> . In which, FFTNet is trained as a student network to learn the intelligibility modifications from SSDRC teacher module. Resulting to a noise robust intelligibility modification of input speech.
Both causal and non-causal versions were experimented in the paper and were found non-causal architecture is more robust.

Although the model was trained on Greek Harvard corpu in the paper for evaluation purpose with native listeners, few samples from the same network (noncausal FFTNet) trained on English data set for ICASSP2020 Show&Tell session is displayed <a href="https://www.csd.uoc.gr/~shifaspv/ICASSP2020-Demo.html">here</a>. In there, the method called "SigPro" is the MBSSDRC method in the paper and "NeuralNet" is the non-causal FFTNet.  

## Implemented On
Python - 3.6.8 <br>
Tensorflow - 1.14.0 <br>

We required few more very common Python packages, check the ```required.txt``` file and install if you don't have.
## Data set
The model displayed was trained on the clean samples from <a href="https://datashare.is.ed.ac.uk/handle/10283/1942">here</a>. 

Extract data to ```./data/NSDTSEA``` folderr, and generate parallel labels with the SSDRC algorithm. 

You may use ```./data/generate_wave_id_list.py``` script to generate training and testing ID lists, and confirm that the names match to the ones in ```./config/config_params.json```

## Description of the ```./config/config_params.json``` file variables
<table>
  <tr>
    <th>"Name"</th>
    <th>"Discription"</th>
  </tr>
  
  <tr>
    <th>train_id_list:</th>
      <td>list of training wave files ID</td>
  </tr>
    <tr>
    <th>valid_id_list:</th>
      <td>list of validation files ID</td>
  </tr>
  <tr>
    <th>n_channels</th>
    <td>number of channels in each layer</td>
  </tr>
<tr>
    <th>dilations</th>
    <td>dilation rate starting from the begining layer</td>
  </tr>
  <tr>
    <th>target_length</th>
      <td> total samples generated in a single forward epoch</td>
  </tr>
    <tr>
    <th>filter_length</th>
    <td>convolutiona filter width: 3 for non-causal architecture </td>
  </tr>
  <tr>
    <th>Regain</th>
      <td>The level to which wave files are RMS normalised </td>
  </tr>
</table>

The **train_id_list** and **valid_id_list** are generated by ```./data/generate_wave_id_list.py``` file.
## Training the model

Go to the ```./src``` folder and run the ```train.py``` or copy the command below to command line 

```
python train.py
```

Optionally, you can resume the training that could not have been completed, by passing the second argument ```model_id```

```
python train.py --model_id=saved_model_id
```

Trained models will be saved to the ```./saved_models``` directory

## Testing the model

You can use the trained model in ```./saved_model``` directory, or your own trained model.
Go to the ```./src``` folder, and compile the ```generate.sh``` file with first argument as the ID of the saved model, like 1 or 2 ..

```
./generate.sh model_id
```

A new folder named ```./outputs/model_id``` will be created and saved the output sample.
User must manually edit the wave file ID inside the ```generate.sh```, to automatically read from the test set.




